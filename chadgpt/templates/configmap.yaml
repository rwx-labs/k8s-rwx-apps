apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "chadgpt.fullname" . }}
data:
  config.yaml: |
    ---
    irc:
      # The hostname or IP address of the IRC server.
      host: {{ .Values.irc.host | required "irc.host is required" | quote }}
      # The port number of the IRC server.
      port: {{ .Values.irc.port | required "irc.port is required" | int }}
      # Use a secure connection.
      tls: {{ ternary "true" "false" .Values.irc.tls }}
      # The nickname used by the bot.
      nick: {{ default "chad" .Values.irc.nick | quote }}
      # The username used by the bot.
      username: {{ default "chad" (default "chad" .Values.irc.nick) | quote }}
      # The version response to CTCP VERSION requests.
      version: "github.com/rwx-labs/chadgpt"
      # List of channels to join when initially connected.
      channels:
        {{- .Values.irc.channels | required "irc.channels must be a list of channels" | toYaml | nindent 8 }}
      # List of nicknames to ignore messages from.
      ignored_nicks:
        {{- .Values.irc.ignored_nicks | required "irc.ignored_nicks must be a list of nicknames" | toYaml | nindent 8 }}

    # Configuration for the GPT completion requests.
    # Reference: https://beta.openai.com/docs/api-reference/completions
    openai:
      # The identifier of the model to use for completions.
      model: {{ .Values.openai.model | quote }}

      # What sampling temperature to use, between 0 and 2. Higher values like 0.8
      # will make the output more random, while lower values like 0.2 will make it
      # more focused and deterministic.
      # temperature: 1

      # The maximum number of tokens to generate in the chat completion.
      max_tokens: {{ .Values.openai.max_tokens }}

      # An alternative to sampling with temperature, called nucleus sampling, where
      # the model considers the results of the tokens with top_p probability mass.
      # So 0.1 means only the tokens comprising the top 10% probability mass are
      # considered.
      #
      # It's recommended to use this or `temperature`, but not both.
      # top_p: 1

      # Number between -2.0 and 2.0. Positive values penalize new tokens based on
      # whether they appear in the text so far, increasing the model's likelihood to
      # talk about new topics.
      # presence_penalty: 0.0

      # Number between -2.0 and 2.0. Positive values penalize new tokens based on
      # their existing frequency in the text so far, decreasing the model's
      # likelihood to repeat the same line verbatim.
      # frequency_penalty: 0.5

      # List of messages used for instructing GPT.
      #
      # Each message has `content` which will be templated with Mustache.
      #
      # Available variables:
      # `message` - The message a user sent to the bot (not including the bot nick)
      # `rawMessage` - The message a user sent to the bot, including the bot nick
      # `channel` - The name of the channel the message was sent in.
      # `nick` - The nickname of the sender.
      messages:
        {{- .Values.openai.messages | required ".openai.messages must be a list of messages with role and content" | toYaml | nindent 8 }}
